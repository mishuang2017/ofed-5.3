From: Valentine Fatiev <valentinef@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/hw/mlx5/qp.c

Change-Id: Ib17daa6d168451c91ce44d2e063166d37a4b14ed
---
 drivers/infiniband/hw/mlx5/qp.c | 20 +++++++++++++++++++-
 1 file changed, 19 insertions(+), 1 deletion(-)

diff --git a/drivers/infiniband/hw/mlx5/qp.c b/drivers/infiniband/hw/mlx5/qp.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@ -30,6 +30,7 @@
  * SOFTWARE.
  */
 
+#include <linux/etherdevice.h>
 #include <linux/module.h>
 #include <rdma/ib_umem.h>
 #include <rdma/ib_cache.h>
@@ -928,7 +929,11 @@ static int mlx5_ib_umem_get(struct mlx5_ib_dev *dev, struct ib_udata *udata,
 {
 	int err;
 
+#ifdef HAVE_MMU_INTERVAL_NOTIFIER
 	*umem = ib_umem_get_peer(&dev->ib_dev, addr, size, 0, 0);
+#else
+	*umem = ib_umem_get_peer(udata, addr, size, 0, 0);
+#endif
 	if (IS_ERR(*umem)) {
 		mlx5_ib_dbg(dev, "umem_get failed\n");
 		return PTR_ERR(*umem);
@@ -985,7 +990,11 @@ static int create_user_rq(struct mlx5_ib_dev *dev, struct ib_pd *pd,
 	if (!ucmd->buf_addr)
 		return -EINVAL;
 
+#ifdef HAVE_MMU_INTERVAL_NOTIFIER
 	rwq->umem = ib_umem_get(&dev->ib_dev, ucmd->buf_addr, rwq->buf_size, 0);
+#else
+	rwq->umem = ib_umem_get(udata, ucmd->buf_addr, rwq->buf_size, 0);
+#endif
 	if (IS_ERR(rwq->umem)) {
 		mlx5_ib_dbg(dev, "umem_get failed\n");
 		err = PTR_ERR(rwq->umem);
@@ -2081,7 +2090,7 @@ static int create_user_qp(struct mlx5_ib_dev *dev, struct ib_pd *pd,
 	struct mlx5_ib_qp_base *base;
 	int mlx5_st;
 	void *qpc;
-	u32 *in;
+	u32 *in = NULL;
 	int err;
 
 	spin_lock_init(&qp->sq.lock);
@@ -5551,9 +5560,18 @@ static void handle_drain_completion(struct ib_cq *cq,
 		if (triggered) {
 			/* Wait for any scheduled/running task to be ended */
 			switch (cq->poll_ctx) {
+#if IS_ENABLED(CONFIG_IRQ_POLL) || !defined(HAVE_IRQ_POLL_H)
 			case IB_POLL_SOFTIRQ:
+#if defined(HAVE_IRQ_POLL_H)
+#if IS_ENABLED(CONFIG_IRQ_POLL)
 				irq_poll_disable(&cq->iop);
 				irq_poll_enable(&cq->iop);
+#endif
+#else
+				blk_iopoll_disable(&cq->iop);
+				blk_iopoll_enable(&cq->iop);
+#endif
+#endif
 				break;
 			case IB_POLL_WORKQUEUE:
 				cancel_work_sync(&cq->work);
