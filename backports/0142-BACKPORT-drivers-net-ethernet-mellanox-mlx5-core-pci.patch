From: Valentine Fatiev <valentinef@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c

Change-Id: I52dd70a8f46290789ed0f53b9865d6d6e1773bb6
---
 .../net/ethernet/mellanox/mlx5/core/pci_irq.c | 106 +++++++++++++++++-
 1 file changed, 104 insertions(+), 2 deletions(-)

diff --git a/drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c b/drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c
@@ -100,13 +100,21 @@ static void irq_set_name(char *name, int vecidx)
 
 static int request_irqs(struct mlx5_core_dev *dev, int nvec)
 {
+#ifndef HAVE_PCI_IRQ_API
+	struct mlx5_priv *priv  = &dev->priv;
+#endif
 	char name[MLX5_MAX_IRQ_NAME];
 	int err;
 	int i;
 
 	for (i = 0; i < nvec; i++) {
 		struct mlx5_irq *irq = mlx5_irq_get(dev, i);
+#ifdef HAVE_PCI_IRQ_API
 		int irqn = pci_irq_vector(dev->pdev, i);
+#else
+		struct msix_entry *msix = priv->msix_arr;
+		int irqn                 = msix[i].vector;
+#endif
 
 		irq_set_name(name, i);
 		ATOMIC_INIT_NOTIFIER_HEAD(&irq->nh);
@@ -124,7 +132,12 @@ static int request_irqs(struct mlx5_core_dev *dev, int nvec)
 err_request_irq:
 	while (i--) {
 		struct mlx5_irq *irq = mlx5_irq_get(dev, i);
+#ifdef HAVE_PCI_IRQ_API
 		int irqn = pci_irq_vector(dev->pdev, i);
+#else
+		struct msix_entry *msix = priv->msix_arr;
+		int irqn                 = msix[i].vector;
+#endif
 
 		free_irq(irqn, &irq->nh);
 	}
@@ -175,8 +188,13 @@ static int irq_set_rmap(struct mlx5_core_dev *mdev)
 
 	vecidx = MLX5_IRQ_VEC_COMP_BASE;
 	for (; vecidx < irq_table->nvec; vecidx++) {
+#ifdef HAVE_PCI_IRQ_API
 		err = irq_cpu_rmap_add(irq_table->rmap,
 				       pci_irq_vector(mdev->pdev, vecidx));
+#else
+		err = irq_cpu_rmap_add(irq_table->rmap,
+				       mdev->priv.msix_arr[vecidx].vector);
+#endif
 		if (err) {
 			mlx5_core_err(mdev, "irq_cpu_rmap_add failed. err %d",
 				      err);
@@ -196,12 +214,21 @@ err_out:
 
 static int set_comp_irq_affinity_hint(struct mlx5_core_dev *mdev, int i)
 {
+#ifndef HAVE_PCI_IRQ_API
+	struct mlx5_priv *priv  = &mdev->priv;
+	struct msix_entry *msix;
+#endif
 	int vecidx = MLX5_IRQ_VEC_COMP_BASE + i;
 	struct mlx5_irq *irq;
 	int irqn;
 
 	irq = mlx5_irq_get(mdev, vecidx);
-	irqn = pci_irq_vector(mdev->pdev, vecidx);
+#ifdef HAVE_PCI_IRQ_API
+		irqn = pci_irq_vector(mdev->pdev, vecidx);
+#else
+		msix = priv->msix_arr;
+		irqn                 = msix[vecidx].vector;
+#endif
 	if (!zalloc_cpumask_var(&irq->mask, GFP_KERNEL)) {
 		mlx5_core_warn(mdev, "zalloc_cpumask_var failed");
 		return -ENOMEM;
@@ -219,12 +246,21 @@ static int set_comp_irq_affinity_hint(struct mlx5_core_dev *mdev, int i)
 
 static void clear_comp_irq_affinity_hint(struct mlx5_core_dev *mdev, int i)
 {
+#ifndef HAVE_PCI_IRQ_API
+	struct mlx5_priv *priv  = &mdev->priv;
+	struct msix_entry *msix;
+#endif
 	int vecidx = MLX5_IRQ_VEC_COMP_BASE + i;
 	struct mlx5_irq *irq;
 	int irqn;
 
 	irq = mlx5_irq_get(mdev, vecidx);
-	irqn = pci_irq_vector(mdev->pdev, vecidx);
+#ifdef HAVE_PCI_IRQ_API
+		irqn = pci_irq_vector(mdev->pdev, vecidx);
+#else
+		msix = priv->msix_arr;
+		irqn                 = msix[vecidx].vector;
+#endif
 	irq_set_affinity_hint(irqn, NULL);
 	free_cpumask_var(irq->mask);
 }
@@ -278,8 +314,13 @@ static void unrequest_irqs(struct mlx5_core_dev *dev)
 	int i;
 
 	for (i = 0; i < table->nvec; i++)
+#ifdef HAVE_PCI_IRQ_API
 		free_irq(pci_irq_vector(dev->pdev, i),
 			 &mlx5_irq_get(dev, i)->nh);
+#else
+		free_irq(dev->priv.msix_arr[i].vector,
+			 &mlx5_irq_get(dev, i)->nh);
+#endif
 }
 
 int mlx5_irq_table_create(struct mlx5_core_dev *dev)
@@ -291,6 +332,9 @@ int mlx5_irq_table_create(struct mlx5_core_dev *dev)
 	int max_comp_eqs;
 	int nvec;
 	int err;
+#ifndef HAVE_PCI_IRQ_API
+	int i;
+#endif
 
 	if (mlx5_core_is_sf(dev))
 		return 0;
@@ -312,9 +356,21 @@ int mlx5_irq_table_create(struct mlx5_core_dev *dev)
 		return -ENOMEM;
 
 	table->irq = kcalloc(nvec, sizeof(*table->irq), GFP_KERNEL);
+#ifdef HAVE_PCI_IRQ_API
 	if (!table->irq)
 		return -ENOMEM;
+#else
+	priv->msix_arr = kcalloc(nvec, sizeof(*priv->msix_arr), GFP_KERNEL);
+	if (!priv->msix_arr || !table->irq) {
+		err = -ENOMEM;
+		goto err_free_irq;
+	}
 
+	for (i = 0; i < nvec; i++)
+		priv->msix_arr[i].entry = i;
+#endif
+
+#ifdef HAVE_PCI_IRQ_API
 	nvec = pci_alloc_irq_vectors(dev->pdev, MLX5_IRQ_VEC_COMP_BASE + 1,
 				     nvec, PCI_IRQ_MSIX);
 	if (nvec < 0) {
@@ -323,6 +379,32 @@ int mlx5_irq_table_create(struct mlx5_core_dev *dev)
 	}
 
 	table->nvec = nvec;
+#else /* HAVE_PCI_IRQ_API */
+#ifdef HAVE_PCI_ENABLE_MSIX_RANGE
+	nvec = pci_enable_msix_range(dev->pdev, priv->msix_arr,
+			MLX5_IRQ_VEC_COMP_BASE + 1, nvec);
+	if (nvec < 0) {
+		err = nvec;
+		goto err_free_irq;
+	}
+
+	table->nvec = nvec;
+#else /* HAVE_PCI_ENABLE_MSIX_RANGE */
+retry:
+	table->nvec = nvec;
+	err = pci_enable_msix(dev->pdev, priv->msix_arr, nvec);
+	if (err < 0) {
+		goto err_free_irq;
+	} else if (err > 2) {
+		nvec = err;
+		goto retry;
+	} else if (err) {
+		mlx5_core_err(dev, "Can't enable the minimum required num of MSIX, %d\n", err);
+		goto err_free_irq;
+	}
+	mlx5_core_dbg(dev, "received %d MSI vectors out of %d requested\n", err, nvec);
+#endif /* HAVE_PCI_ENABLE_MSIX_RANGE */
+#endif /* HAVE_PCI_IRQ_API */
 
 	err = irq_set_rmap(dev);
 	if (err)
@@ -345,15 +427,25 @@ err_set_affinity:
 err_request_irqs:
 	irq_clear_rmap(dev);
 err_set_rmap:
+#ifdef HAVE_PCI_IRQ_API
 	pci_free_irq_vectors(dev->pdev);
+#else
+	pci_disable_msix(dev->pdev);
+#endif
 err_free_irq:
 	kfree(table->irq);
+#ifndef HAVE_PCI_IRQ_API
+	kfree(priv->msix_arr);
+#endif
 	return err;
 }
 
 void mlx5_irq_table_destroy(struct mlx5_core_dev *dev)
 {
 	struct mlx5_irq_table *table = dev->priv.irq_table;
+#ifndef HAVE_PCI_IRQ_API
+	struct mlx5_priv *priv  = &dev->priv;
+#endif
 	int i;
 
 	if (mlx5_core_is_sf(dev))
@@ -366,9 +458,19 @@ void mlx5_irq_table_destroy(struct mlx5_core_dev *dev)
 	irq_clear_rmap(dev);
 	clear_comp_irqs_affinity_hints(dev);
 	for (i = 0; i < table->nvec; i++)
+#ifdef HAVE_PCI_IRQ_API
 		free_irq(pci_irq_vector(dev->pdev, i),
 			 &mlx5_irq_get(dev, i)->nh);
+#else
+		free_irq(dev->priv.msix_arr[i].vector,
+			 &mlx5_irq_get(dev, i)->nh);
+#endif
+#ifdef HAVE_PCI_IRQ_API
 	pci_free_irq_vectors(dev->pdev);
+#else
+	pci_disable_msix(dev->pdev);
+	kfree(priv->msix_arr);
+#endif
 	kfree(table->irq);
 }
 
